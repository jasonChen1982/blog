---
title: 光线追踪
date: 2015-10-02
---


可能每个喜欢计算机图形学的程序员都有一个实现光线追踪的梦，本文将利用`canvas2d`的api来实现一个简单的js版的光线追踪。

## 什么叫光线追踪

光线追踪可以理解成是一种以基于光线传播的形势来计算和渲染三维场景中物体可见表面的颜色值，它的处理单元可以理解成光线`光线(ray)` 。

与我们常见的`D3D` 、`opengl` 等API不同，这些我们熟知的方法一般都运用于`实时的图形渲染场景(real-time rendering)`，大都采用`光栅化(rasterization)`机制来渲染大量的三角形，任何三维物体的最小组成单位是三角形，通过在三角形上进行各种向量的插值、纹理采样来绘制三维物体。并且这种基于光栅化机制的渲染方案只支持局部光照系统，不能很简单、干脆的实现类似 `阴影(shadow)`、`反射(reflection)`、`折射(refraction)` 等现实场景中的常见效果的渲染。只能通过类似`阴影贴图(shadow mapping)`、`环境贴图(environment mapping)`等技术来曲线的实现。

而光线追踪则不同，光线追踪的从观察点向三维场景中发射光线 ，来捕获并计算场景中物体可见部位的颜色，并可以在实现原理上通过加入相应的阴影、反射、折射的计算公式来轻松的搞定这些效果。本文讲介绍光线追踪解决方案中的一种：`光线追踪(ray tracing)` 

## 原理 

之前说了，光线追踪与我们熟悉的光栅化渲染方式不一样，我们熟悉的光栅化渲染方式的原理简单来说是把所有的三维物体以三角形为单位来近似的描述三维物体的表面，然后经过对三角形的各种仿射变换、`backface` 检测、插值和纹理采样、 光栅化、深度缓冲区的过滤、模版缓冲区、合成计算将最终的颜色呈现在屏幕上。

光线追踪是一个完全不一样的思路，光线追踪是利用了物理中的`光路的可逆性`来实现三维场景的渲染，主要原理是从观察者的眼睛的位置发射一条经过投影平面的射线，然后计算这条射线与场景中的三维物体的相交，再根据该相交点的材质、法线、反射、折射、以及阴影检测来综合计算该点的颜色值。原理图如下：

[ray-tracing]: 



